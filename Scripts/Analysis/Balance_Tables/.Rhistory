#   long_data <- long_data %>%
#     rename(group = treatment_group)
#
# joint_long_data
balance_df
?mlogit
vars_to_include <- c("hh_age_h", "hh_education_level_bin_h", "hh_education_skills_5_h",
"hh_gender_h", "hh_numero", "hh_03_", "hh_10_", "hh_12_6_", "hh_16_",
"hh_15_2", "hh_26_", "hh_29_01", "hh_29_02", "hh_29_03", "hh_29_04",
"hh_37_", "hh_38_", "living_01_bin", "game_A_total", "game_B_total",
"TLU", "agri_6_15", "agri_6_32_bin", "agri_6_36_bin", "total_land_ha",
"agri_6_34_comp_any", "agri_income_05", "beliefs_01_bin",
"beliefs_02_bin", "beliefs_03_bin", "beliefs_04_bin", "beliefs_05_bin",
"beliefs_06_bin", "beliefs_07_bin", "beliefs_08_bin", "beliefs_09_bin",
"health_5_3_bin", "health_5_6_", "num_water_access_points", "q_51")
ml_balance_df <- mlogit.data(balance_df, choice = "treatment_group")
data("Fishing", package = "mlogit")
Fish <- dfidx(Fishing, varying = 2:9, shape = "wide", choice = "mode")
## a pure "conditional" model
summary(mlogit(mode ~ price + catch, data = Fish))
#
Fish
vars_to_include <- c("hh_age_h", "hh_education_level_bin_h", "hh_education_skills_5_h",
"hh_gender_h", "hh_numero", "hh_03_", "hh_10_", "hh_12_6_", "hh_16_",
"hh_15_2", "hh_26_", "hh_29_01", "hh_29_02", "hh_29_03", "hh_29_04",
"hh_37_", "hh_38_", "living_01_bin", "game_A_total", "game_B_total",
"TLU", "agri_6_15", "agri_6_32_bin", "agri_6_36_bin", "total_land_ha",
"agri_6_34_comp_any", "agri_income_05", "beliefs_01_bin",
"beliefs_02_bin", "beliefs_03_bin", "beliefs_04_bin", "beliefs_05_bin",
"beliefs_06_bin", "beliefs_07_bin", "beliefs_08_bin", "beliefs_09_bin",
"health_5_3_bin", "health_5_6_", "num_water_access_points", "q_51")
ml_balance_df <- multinom(balance_df, choice = "treatment_group")
library(nnet)       # For multinom()
library(sandwich)   # For robust clustered SEs
library(lmtest)     # For hypothesis testing
# Example dataset
set.seed(123)
balance_df <- data.frame(
treatment_group = factor(sample(1:3, 100, replace = TRUE)),  # Multinomial outcome
predictor1 = rnorm(100),
predictor2 = rnorm(100),
hhid_village = sample(1:20, 100, replace = TRUE)  # Clustering variable
)
# Define formula and run multinomial logit model
formula <- treatment_group ~ predictor1 + predictor2
model <- multinom(formula, data = balance_df)
# Compute clustered standard errors at the village level
cluster_se <- vcovCL(model, cluster = ~hhid_village, data = balance_df, type = "HC0")
library(mclogit)
# Example dataset
set.seed(123)
balance_df <- data.frame(
treatment_group = factor(sample(1:3, 100, replace = TRUE)),  # Multinomial outcome
predictor1 = rnorm(100),
predictor2 = rnorm(100),
hhid_village = sample(1:20, 100, replace = TRUE)  # Clustering variable
)
# Fit multinomial logistic regression
formula <- treatment_group ~ predictor1 + predictor2
model <- multinom(formula, data = balance_df)
# Fit multinomial logistic model using mblogit (supports clustering)
model_mclogit <- mblogit(treatment_group ~ predictor1 + predictor2, data = balance_df, random = ~ 1 | hhid_village)
# Display clustered SEs
summary(model_mclogit)
?mblogit
library(mclogit)
library(sandwich)
library(lmtest)
# Example dataset
set.seed(123)
balance_df <- data.frame(
treatment_group = factor(sample(1:3, 100, replace = TRUE)),  # Multinomial outcome
predictor1 = rnorm(100),
predictor2 = rnorm(100),
hhid_village = sample(1:20, 100, replace = TRUE)  # Clustering variable
)
# Fit multinomial logistic regression model
model_mclogit <- mblogit(treatment_group ~ predictor1 + predictor2,
data = balance_df)
# Compute clustered standard errors at the village level
clustered_vcov <- vcovCL(model_mclogit, cluster = ~hhid_village, data = balance_df, type = "HC0")
# Install from CRAN
install.packages("fixest")
#install.packages("writexl")
#install.packages("mclogit")
#install.packages("clusterSEs")
library(clusterSEs)
library(mlogit)
library(writexl) #to output to excel doc
library(dplyr)
library(readr) #to read in dta's
library(tidyr)
library(haven)
library(data.table)
library(tidyverse)
library(estimatr)
library(broom)
library(kableExtra) #to output to HTML tables
library(sandwich) #to wrangle data
library(lmtest)  # For likelihood ratio test
library(stats)   #for FDR q-stats
library(nnet)  #to use multilogit regression
library(car)
library(aod)
# Define the file paths
proj_paths <- list(
projects = "C:/Users/Kateri/Box/NSF Senegal",
alternative_projects = "C:/Users/km978/Box/NSF Senegal"
)
# Check if the Kateri path exists and resolve the project path accordingly
if (file.exists(proj_paths$projects)) {
proj <- kwb.utils::resolve(list(
projects = proj_paths$projects,
p1 = "<projects>/Data_Management/Output/Analysis/Balance_Tables"
))
} else {
proj <- kwb.utils::resolve(list(
projects = proj_paths$alternative_projects,
p1 = "<projects>/Data_Management/Output/Analysis/Balance_Tables"
))
}
file_path_balance_tables_df <- file.path(proj$p1, "baseline_balance_tables_data_PAP.dta")
balance_df <- read_dta(file_path_balance_tables_df)
balance_df
# Adding a single categorical variable for household training categories - this is for computing summary stats since I'm keeping the trained_hh variable
joint_df <- balance_df %>%
mutate(
group = str_sub(hhid, 3, 4),
treatment_group = case_when(
group %in% c("0A", "0B") ~ "Control",
group %in% c("1A", "1B") ~ "Treatment1",
group %in% c("2A", "2B") ~ "Treatment2",
group %in% c("3A", "3B") ~ "Treatment3",
)
) %>% select(-group)
names(joint_df)
# joint_long_data <- joint_df %>%
#   pivot_longer(
#     cols = -c(hhid, hhid_village, treatment_group),  # Keep hhid and group as is, pivot all other columns
#     names_to = "variable",    # Create a column named "variable" for former column names
#     values_to = "value"       # Store values in a column named "value"
#   )
#
#   joint_long_data <- joint_long_data %>%
#     rename(group = treatment_group)
# view(joint_long_data)
summary_df <- balance_df %>%
mutate(
group = str_sub(hhid, 3, 4),
treatment_group = case_when(
group %in% c("0A", "0B") ~ "Control",
group %in% c("1A", "1B") ~ "Treatment1",
group %in% c("2A", "2B") ~ "Treatment2",
group %in% c("3A", "3B") ~ "Treatment3",
group %in% c("1A", "1B", "2A", "2B", "3A", "3B") & trained_hh == 0 ~ "Local Control"
)
) %>% select(-group)
# long_data_sum <- summary_df %>%
#   pivot_longer(
#     cols = -c(hhid, hhid_village, treatment_group),  # Keep hhid and group as is, pivot all other columns
#     names_to = "variable",    # Create a column named "variable" for former column names
#     values_to = "value"       # Store values in a column named "value"
#   )
#
#   long_data_sum <- long_data_sum %>%
#     rename(group = treatment_group)
# Adding a single categorical variable for household training categories - this is for running regressions to avoid multicollinearity with trained_hh
balance_df <- balance_df %>%
mutate(
# Extract the two middle characters (e.g., 2A) from hhid
group = str_sub(hhid, 3, 4),
# Assign treatment group, ensuring "Local Control" is prioritized
treatment_group = case_when(
group %in% c("0A", "0B") ~ "Control",
group %in% c("1A", "1B") ~ "Treatment1",
group %in% c("2A", "2B") ~ "Treatment2",
group %in% c("1A", "1B", "2A", "2B", "3A", "3B") & trained_hh == 0 ~ "Local Control",  # Moved to the top
group %in% c("3A", "3B") ~ "Treatment3"
)
) %>% select(-group)
balance_df
#
# long_data <- balance_df %>%
#   pivot_longer(
#     cols = -c(hhid, hhid_village, treatment_group),  # Keep hhid and group as is, pivot all other columns
#     names_to = "variable",    # Create a column named "variable" for former column names
#     values_to = "value"       # Store values in a column named "value"
#   )
#
#   long_data <- long_data %>%
#     rename(group = treatment_group)
#
# joint_long_data
# Install from CRAN
install.packages("fixest")
#install.packages("writexl")
#install.packages("mclogit")
#install.packages("clusterSEs")
install.packages("fixest")
library(clusterSEs)
library(mlogit)
library(writexl) #to output to excel doc
library(dplyr)
library(readr) #to read in dta's
library(tidyr)
library(haven)
library(data.table)
library(tidyverse)
library(estimatr)
library(broom)
library(kableExtra) #to output to HTML tables
library(sandwich) #to wrangle data
library(lmtest)  # For likelihood ratio test
library(stats)   #for FDR q-stats
library(nnet)  #to use multilogit regression
library(car)
library(aod)
#install.packages("writexl")
#install.packages("mclogit")
#install.packages("clusterSEs")
install.packages("fixest")
library(clusterSEs)
library(mlogit)
library(writexl) #to output to excel doc
library(dplyr)
library(readr) #to read in dta's
library(tidyr)
library(haven)
library(data.table)
library(tidyverse)
library(estimatr)
library(broom)
library(kableExtra) #to output to HTML tables
library(sandwich) #to wrangle data
library(lmtest)  # For likelihood ratio test
library(stats)   #for FDR q-stats
library(nnet)  #to use multilogit regression
library(car)
library(aod)
install.packages("fixest")
library(fixest)
library(mclogit)
library(sandwich)
library(lmtest)
library(dplyr)
set.seed(123)
balance_df <- data.frame(
treatment_group = factor(sample(1:3, 100, replace = TRUE)),  # Multinomial outcome
predictor1 = rnorm(100),
predictor2 = rnorm(100),
hhid_village = sample(1:20, 100, replace = TRUE)  # Clustering variable
)
# Fit multinomial logit model
model_mclogit <- mblogit(treatment_group ~ predictor1 + predictor2,
data = balance_df)
# Function to compute clustered standard errors
clustered_se_fn <- function(model, cluster_var) {
# Extract model matrix
X <- model.matrix(model)
# Get residuals manually
probs <- predict(model, type = "prob")
Y <- model.response(model.frame(model))
# Convert Y to a matrix of 0s and 1s
Y_mat <- model.matrix(~ Y - 1)
# Compute score residuals (difference between observed and predicted)
score_mat <- (Y_mat - probs) * X
# Aggregate by cluster
cluster_groups <- split(score_mat, cluster_var)
meat <- Reduce("+", lapply(cluster_groups, function(x) crossprod(colMeans(x))))
# Compute variance-covariance matrix (sandwich estimator)
bread <- solve(crossprod(X))  # Inverse Fisher Information
clustered_vcov <- bread %*% meat %*% bread
return(clustered_vcov)
}
# Apply function to compute clustered SEs
clustered_vcov <- clustered_se_fn(model_mclogit, balance_df$hhid_village)
library(nnet)        # For multinom()
library(lmtest)      # For hypothesis testing
library(sandwich)    # For robust variance estimation
# Example dataset
set.seed(123)
balance_df <- data.frame(
treatment_group = factor(sample(1:3, 100, replace = TRUE)),  # Multinomial outcome
predictor1 = rnorm(100),
predictor2 = rnorm(100),
hhid_village = sample(1:20, 100, replace = TRUE)  # Clustering variable
)
# Fit multinomial logistic regression
formula <- treatment_group ~ predictor1 + predictor2
model <- multinom(formula, data = balance_df)
# Function to compute clustered standard errors
cluster_se_fn <- function(model, cluster) {
# Extract coefficients
coef_matrix <- coef(model)
# Get number of observations and parameters
num_obs <- nrow(model.frame(model))
num_params <- length(coef_matrix)
# Compute the meat of the sandwich estimator (score contributions)
X <- model.matrix(model)  # Design matrix
probs <- predict(model, type = "probs")  # Predicted probabilities
Y <- model.response(model.frame(model))  # True response variable
# Convert Y to a matrix of 0s and 1s for multinomial classification
Y_mat <- model.matrix(~ Y - 1)
# Compute score residuals
score_mat <- (Y_mat - probs) * X  # Contribution per observation
# Aggregate score residuals by cluster
cluster_groups <- split(score_mat, cluster)
meat <- Reduce("+", lapply(cluster_groups, function(x) crossprod(colMeans(x))))
# Compute sandwich variance estimator
bread <- solve(crossprod(X, probs * (1 - probs) * X))  # Inverse Fisher Information
clustered_vcov <- bread %*% meat %*% bread
return(clustered_vcov)
}
# Compute clustered standard errors
clustered_se <- cluster_se_fn(model, balance_df$hhid_village)
#install.packages("writexl")
#install.packages("mclogit")
#install.packages("clusterSEs")
#install.packages("fixest")
library(fixest)
library(clusterSEs)
library(mlogit)
library(writexl) #to output to excel doc
library(dplyr)
library(readr) #to read in dta's
library(tidyr)
library(haven)
library(data.table)
library(tidyverse)
library(estimatr)
library(broom)
library(kableExtra) #to output to HTML tables
library(sandwich) #to wrangle data
library(lmtest)  # For likelihood ratio test
library(stats)   #for FDR q-stats
library(nnet)  #to use multilogit regression
library(car)
library(aod)
# Define the file paths
proj_paths <- list(
projects = "C:/Users/Kateri/Box/NSF Senegal",
alternative_projects = "C:/Users/km978/Box/NSF Senegal"
)
# Check if the Kateri path exists and resolve the project path accordingly
if (file.exists(proj_paths$projects)) {
proj <- kwb.utils::resolve(list(
projects = proj_paths$projects,
p1 = "<projects>/Data_Management/Output/Analysis/Balance_Tables"
))
} else {
proj <- kwb.utils::resolve(list(
projects = proj_paths$alternative_projects,
p1 = "<projects>/Data_Management/Output/Analysis/Balance_Tables"
))
}
file_path_balance_tables_df <- file.path(proj$p1, "baseline_balance_tables_data_PAP.dta")
balance_df <- read_dta(file_path_balance_tables_df)
balance_df
compute_summary_stats <- function(df) {
df %>%
group_by(group, variable) %>%
summarise(
mean_value = round(mean(value, na.rm = TRUE), 2),
sd_value = round(sd(value, na.rm = TRUE), 2),
N = sum(!is.na(value)),  # Count of non-missing values
.groups = "drop"
) %>%
pivot_longer(cols = c(mean_value, sd_value, N), names_to = "stat_type", values_to = "stat_value") %>%
mutate(stat_type = case_when(
stat_type == "mean_value" ~ "Mean",
stat_type == "sd_value" ~ "SD",  # SD should come before N
stat_type == "N" ~ "N"
)) %>%
mutate(stat_type = factor(stat_type, levels = c("Mean", "SD", "N"))) %>%  # Set order
arrange(variable, stat_type) %>%
pivot_wider(names_from = group, values_from = stat_value) %>%
select(variable, stat_type, everything())  # Ensure variable and stat_type come first
}
# compute_summary_stats <- function(df) {
#   df %>%
#     group_by(group, variable) %>%
#     summarise(
#       mean_value = round(mean(value, na.rm = TRUE), 2),
#       sd_value = round(sd(value, na.rm = TRUE), 2),
#       .groups = "drop"  # Prevents group structure from persisting
#     ) %>%
#     pivot_longer(cols = c(mean_value, sd_value), names_to = "stat_type", values_to = "stat_value") %>%
#     mutate(stat_type = ifelse(stat_type == "mean_value", "Mean", "SD")) %>%
#     pivot_wider(names_from = group, values_from = stat_value) %>%
#     arrange(variable, stat_type) %>%
#     # This ensures the 'variable' and 'stat_type' columns come first
#     select(variable, stat_type, everything()) %>%
#     # Explicitly ensure 'variable' is ordered as it appears in the original data
#     arrange(match(variable, unique(df$variable)))
# }
summary_table1 <- compute_summary_stats(long_data_sum)
# View output
print(summary_table1)
summary_table2 <- summary_table1 %>%
# Remove rows with stat_type == "N" but preserve the 'N_values' column
#filter(stat_type != "N") %>%
# Apply two decimal places for numeric columns (Control, Treatment1, etc.)
mutate(across(where(is.numeric), ~ format(.x, nsmall = 2))) %>%
# Convert everything to character type (for proper formatting)
mutate(across(everything(), as.character)) %>%
# Add parentheses for SD values (only if stat_type is SD)
mutate(across(
Control:Treatment3,  # Apply only to numeric columns
~ ifelse(stat_type == "SD", paste0("(", trimws(.), ")"), .)  # Add parentheses for SD values
)) %>%
# Add 'N_values' column to each of the treatments columns
#mutate(across(Control:Treatment3, ~ ifelse(is.na(N_values), ., N_values), .names = "updated_{.col}")) %>%
# Select necessary columns: variable, N_values, and treatment columns
select(variable, everything()) %>%
#summary_table2 <- summary_table1 %>%
mutate(
variable = ifelse(stat_type %in% c("SD", "N"), "", variable),
stat_type = ifelse(stat_type %in% c("SD", "N"), "", stat_type)
) %>%
select(-stat_type)
summary_table2
summary_table3 <- summary_table2 %>%
mutate(Question = case_when(
variable == "hhid_village" ~ "Village ID",
variable == "hhid" ~ "Household ID",
variable == "trained_hh" ~ "Trained household",
variable == "hh_age_h" ~ "Household head age",
variable == "hh_education_level_bin_h" ~ "Indicator for household head with secondary education or higher (1=Yes, 0=No)",
variable == "hh_education_skills_5_h" ~ "Indicator that household head is literate (1=Yes, 0=No)",
variable == "hh_gender_h" ~ "Household head gender (1=Male, 0=Female)",
variable == "hh_numero" ~ "Household size",
variable == "hh_03_" ~ "Indicator for those who worked in domestic agricultural activities (1=Yes, 0=No) †",
variable == "hh_10_" ~ "Hours per week spent within 1 meter of surface water source",
variable == "hh_12_6_" ~ "Indicator for those who harvested aquatic vegetation, among those who spent time near a water source (1=Yes, 0=No)",
variable == "hh_16_" ~ "Hours spent producing, purchasing, or applying fertilizer",
variable == "hh_15_2" ~ "Indicator for making fertilizer (compost) among those who spent time near a water source (1=Yes, 0=No)",
variable == "hh_26_" ~ "Indicator if currently enrolled in formal school (1=Yes, 0=No, asked about children) †",
variable == "hh_27_" ~ "Indicator if attended non-formal school or training? (1=Yes, 0=No, asked about children) †",
variable == "hh_29_01" ~ "Indicator for primary level education (1=Yes, 0=No, asked about children)",
variable == "hh_29_02" ~ "Indicator for secondary middle level education (1=Yes, 0=No, asked about children)",
variable == "hh_29_03" ~ "Indicator for secondary higher level education (1=Yes, 0=No, asked about children)",
variable == "hh_29_04" ~ "Indicator for upper secondary education (1=Yes, 0=No, asked about children)",
variable == "hh_31_bin" ~ "Indicator if student completed studies or moved to next class (1=Yes, 0=No, asked about children)",
variable == "hh_37_" ~ "Indicator if missed >1 consecutive week of school due to illness? (1=Yes, 0=No, asked about children) †",
variable == "hh_38_" ~ "Number of attended school days in the past week (asked about children)",
variable == "living_01_bin" ~ "Indicator for selected tap water as main drinking source (1=Yes, 0=No)",
variable == "game_A_total" ~ "Total paid for Game A (CFA)",
variable == "game_B_total" ~ "Total paid for Game B (CFA)",
variable == "TLU" ~ "Tropical livestock units",
variable == "agri_6_15" ~ "Number of cultivated plots",
variable == "agri_6_32_bin" ~ "Indicator if used any organic fertilizer (1=Yes, 0=No)",
variable == "agri_6_36_bin" ~ "Indicator if used any inorganic/chemical fertilizer (1=Yes, 0=No)",
variable == "total_land_ha" ~ "Total land cultivated (hectares)",
variable == "agri_6_34_comp_any" ~ "Used any compost on any parcel (1=Yes, 0=No) †",
variable == "agri_income_01" ~ "Indicator if engaged in paid agricultural work in last 12 months (1=Yes, 0=No) †",
variable == "agri_income_05" ~ "Amount received for agricultural work (FCFA)",
variable == "beliefs_01_bin" ~ "Probability of contracting bilharzia (1=Strongly agree/Agree) +",
variable == "beliefs_02_bin" ~ "Probability of household member contracting bilharzia (1=Yes, 0=No) +",
variable == "beliefs_03_bin" ~ "Probability of a child contracting bilharzia (1=Yes, 0=No) +",
variable == "beliefs_04_bin" ~ "Agree: Village land should belong to community (1=Yes, 0=No) +",
variable == "beliefs_05_bin" ~ "Agree: Village water sources should belong to community (1=Yes, 0=No) +",
variable == "beliefs_06_bin" ~ "Agree: Right to products from own land (1=Yes, 0=No) +",
variable == "beliefs_07_bin" ~ "Agree: Right to products from community land worked on (1=Yes, 0=No) +",
variable == "beliefs_08_bin" ~ "Agree: Right to products from community water sources fished in (1=Yes, 0=No) +",
variable == "beliefs_09_bin" ~ "Agree: Right to products from community water sources harvested from (1=Yes, 0=No) +",
variable == "health_5_3_bin" ~ "Indicator for bilharzia or diarrhea in the past 12 months (1=Yes, 0=No, among those reporting illness)",
variable == "health_5_6_" ~ "Indicator for Diagnosed with schistosomiasis (1=Yes, 0=No) †",
variable == "num_water_access_points" ~ "Number of village water access points",
variable == "q_51" ~ "Distance to nearest healthcare center (km) [village level]",
variable == "target_village" ~ "Indicator if auction village (1=Yes, 0=No)",
TRUE ~ variable  # Default case
))
summary_table3
summary_table_complete <- summary_table3 %>% select(Question, everything()) %>%
rename(Variable = variable,
`Private Treatment` = Treatment1,
`Public Treatment` = Treatment2,
`Private and Public Treatment` = Treatment3)
summary_table_complete
#%>%   filter(variable != "target_village")
# Excel spreadsheet
setwd("C:/Users/km978/Box/NSF Senegal/Data_Management/Output/Analysis/Balance_Tables")
# Manually add footnotes as a single row
footnotes <- data.frame(
Variable = "Footnotes:",
Mean = "Table presents mean values, with standard deviations in parentheses.",
SD = "+ Binary variables were created from Likert scale responses based on their distribution.",
Other = "† 'I Don't Know' responses (coded as 2) have been recoded as missing values."
)
# Ensure all columns are character type to avoid coercion issues
summary_table_complete <- summary_table_complete %>%
mutate(across(everything(), as.character))
# Bind footnotes to the summary table
summary_table_with_footnotes <- bind_rows(summary_table, footnotes)
# Save to Excel
write_xlsx(summary_table_with_footnotes, "_baseline_summary_statsV3.xlsx")
# Excel spreadsheet
setwd("C:/Users/km978/Box/NSF Senegal/Data_Management/Output/Analysis/Balance_Tables")
# Manually add footnotes as a single row
footnotes <- data.frame(
Variable = "Footnotes:",
Mean = "Table presents mean values, with standard deviations in parentheses.",
SD = "+ Binary variables were created from Likert scale responses based on their distribution.",
Other = "† 'I Don't Know' responses (coded as 2) have been recoded as missing values."
)
# Ensure all columns are character type to avoid coercion issues
summary_table_complete <- summary_table_complete %>%
mutate(across(everything(), as.character))
# Bind footnotes to the summary table
summary_table_with_footnotes <- bind_rows(summary_table_complete, footnotes)
# Save to Excel
write_xlsx(summary_table_with_footnotes, "_baseline_summary_statsV3.xlsx")
